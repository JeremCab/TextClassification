{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT with TF-IDF features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip # upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U scikit-learn\n",
    "# !pip install -U transformers\n",
    "# !pip install -U datasets\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tqdm progress bars (on a terminal):\n",
    "1. `conda install -c conda-forge nodejs`\n",
    "2. `jupyter labextension install @jupyter-widgets/jupyterlab-manager`\n",
    "3. `jupyter nbextension enable --py widgetsnbextension`\n",
    "4. `jupyter lab clean`\n",
    "5. Refresh web page..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check versions\n",
    "# import sklearn\n",
    "# import transformers\n",
    "# import datasets\n",
    "\n",
    "# print(\"Current versions:\")\n",
    "# print(sklearn.__version__)\n",
    "# print(datasets.__version__)\n",
    "# print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Current versions:\n",
    "1.0.2\n",
    "2.0.0\n",
    "4.18.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import src.model as mod\n",
    "from src.train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device and seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# seeds (torch generator seed missing?)\n",
    "seed = 42 # 1979\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset folder & device\n",
    "dataset_name = 'imdb'  # 'trec'\n",
    "sort = True            # True\n",
    "\n",
    "# Model \n",
    "model_name = 'bert-base-uncased'\n",
    "tfidf_dim = 3000\n",
    "batch_size = 256\n",
    "pooling = 'mean'      # 'mean', 'mean_std', cls', 'mean_cls', 'mean_std_cls'.\n",
    "mode = 'default'      # 'default', 'bert_only', 'tfidf_only'\n",
    "\n",
    "# Learning algo\n",
    "alpha = 10\n",
    "\n",
    "# results\n",
    "results_folder = \"/raid/home/jeremiec/Data/TextClassification\"\n",
    "results_file = os.path.join(results_folder, dataset_name) + '.pkl'\n",
    "cache_dir = os.path.join(results_folder, 'cache_dir_' + dataset_name + '/')\n",
    "\n",
    "if os.path.exists(cache_dir):\n",
    "    os.system(\"rm -rf \" + cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_tmp = torch.rand(size=(100000, 73500), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and tokenize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview of the datasets**\n",
    "1. Sentiment analysis\n",
    "    - ``IMDB``\n",
    "    - ``Yelp. P``\n",
    "    - ``Yelp. F``\n",
    "2. Question classification\n",
    "    - ``TREC``\n",
    "    - ``Yahoo! Answers``\n",
    "3. Topic detection\n",
    "    - ``AG News``\n",
    "    - ``DBPedia``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.02 MiB, post-processed: Unknown size, total: 207.25 MiB) to /raid/home/jeremiec/Data/TextClassification/cache_dir_imdb/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538d573cf03c40efb210c3e1dff5703e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5557f8ad09e497d91f5b4ae9672df0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9b598622a14332b92236a5ce13076d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3f2c8c478e4d0c813e18dd784bd271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imdb downloaded and prepared to /raid/home/jeremiec/Data/TextClassification/cache_dir_imdb/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2affa01295441bb127442de0d038ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031bb038cdf94f68964941daca8454c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbaa4500dd849faa9a68645ec91b8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9abc829e6e4fd7bb56b539a00af888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Sentiment\n",
    "# # IMDB\n",
    "# dataset, tokenizer, model_name = load_and_tokenize_dataset('imdb', model_name=model_name, cache_dir=cache_dir)\n",
    "\n",
    "# # Yelp P. XXX CUDA OoM\n",
    "# dataset, tokenizer, model_name = load_and_tokenize_dataset('yelp_polarity', model_name=model_name, cache_dir=cache_dir)\n",
    "\n",
    "# # Yelp F. XXX CUDA OoM\n",
    "# dataset, tokenizer, model_name = load_and_tokenize_dataset('yelp_review_full', model_name=model_name, cache_dir=cache_dir)\n",
    "\n",
    "\n",
    "# # Question\n",
    "# # TREC\n",
    "# dataset, tokenizer, model_name = load_and_tokenize_dataset('trec', model_name=model_name, cache_dir=cache_dir)\n",
    "\n",
    "# # Yahoo! Answers # XXX\n",
    "# dataset, tokenizer, model_name = load_and_tokenize_dataset('yahoo_answers_topics', model_name=model_name, cache_dir=cache_dir)\n",
    "\n",
    "\n",
    "# # Topic\n",
    "# # AG NEWS\n",
    "# dataset, tokenizer, model_name = load_and_tokenize_dataset('ag_news', model_name=model_name, cache_dir=cache_dir)\n",
    "\n",
    "# # DBPedia # XXX\n",
    "# dataset, tokenizer, model_name = load_and_tokenize_dataset('dbpedia_14', model_name=model_name, cache_dir=cache_dir)\n",
    "\n",
    "\n",
    "\n",
    "dataset, tokenizer, model_name = load_and_tokenize_dataset(dataset_name, \n",
    "                                                           model_name=model_name, \n",
    "                                                           sort=sort,\n",
    "                                                           cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask', 'length'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask', 'length'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask', 'length'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "indices = dataset['train']._indices\n",
    "indices = np.array([i.as_py() for i in indices[0]])\n",
    "indices"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = np.random.rand(indices.shape[0], 10)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = np.array([x[i] for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.939471753484959"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "81450 / 5452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'].set_format(type='torch', columns=['input_ids', \n",
    "                                                 'attention_mask', \n",
    "                                                 'labels', \n",
    "                                                 'length'])\n",
    "\n",
    "# dataset['train'] = dataset['train'].remove_columns(text_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset['train'],\n",
    "                                     # shuffle=False,\n",
    "                                     drop_last=False,\n",
    "                                     batch_size=batch_size,\n",
    "                                     collate_fn=DataCollatorWithPadding(tokenizer)\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7efd45c552e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59110"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pad = 0\n",
    "\n",
    "for b in dataloader:\n",
    "    nb_pad += (b['input_ids'] == 0).sum().item()\n",
    "\n",
    "nb_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features computed in 32.23151969909668 sec.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "dataset = mod.get_tfidf_features(dataset, dim=tfidf_dim)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "tfidf_time = t1 - t0\n",
    "print(f\"Features computed in {tfidf_time} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "model = mod.BertTFIDF(model_name=model_name, pooling=pooling, mode=mode, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00c7562a8b34d1bac4f8e5c23fd281d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Processing data\n",
    "t0 = time.time()\n",
    "\n",
    "X_train, y_train = process_dataset(dataset['train'], model, tokenizer, device, batch_size)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "training_time = t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "# Note: if different alpha are tested, insert a loop here\n",
    "t0 = time.time()\n",
    "\n",
    "learning_algo = RidgeClassifier(alpha=alpha)\n",
    "learning_algo.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "fitting_time = t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OLD VERSION\n",
    "\n",
    "# t0 = time.time()\n",
    "\n",
    "# learning_algo = train_learning_algo(learning_algo, dataset, model, tokenizer, \n",
    "#                                     device, batch_size)\n",
    "\n",
    "# t1 = time.time()\n",
    "\n",
    "# training_time = t1 - t0\n",
    "# print(print(f\"Model trained in {training_time} sec.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c481cc092445ac98f0d434f48ce1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test, y_test_preds = predict(learning_algo, dataset, model, tokenizer, \n",
    "                               device, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9440    0.9586    0.9512     12500\n",
      "         1.0     0.9579    0.9431    0.9505     12500\n",
      "\n",
      "    accuracy                         0.9508     25000\n",
      "   macro avg     0.9509    0.9508    0.9508     25000\n",
      "weighted avg     0.9509    0.9508    0.9508     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "test_results = classification_report(y_test, y_test_preds, digits=4, output_dict=True)\n",
    "print(classification_report(y_test, y_test_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.0': {'precision': 0.9439848735523517,\n",
       "  'recall': 0.95856,\n",
       "  'f1-score': 0.9512166077878776,\n",
       "  'support': 12500},\n",
       " '1.0': {'precision': 0.95791013244495,\n",
       "  'recall': 0.94312,\n",
       "  'f1-score': 0.950457532148184,\n",
       "  'support': 12500},\n",
       " 'accuracy': 0.95084,\n",
       " 'macro avg': {'precision': 0.9509475029986509,\n",
       "  'recall': 0.9508399999999999,\n",
       "  'f1-score': 0.9508370699680309,\n",
       "  'support': 25000},\n",
       " 'weighted avg': {'precision': 0.9509475029986509,\n",
       "  'recall': 0.95084,\n",
       "  'f1-score': 0.9508370699680309,\n",
       "  'support': 25000}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 288.10333919525146 sec.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total training time: {tfidf_time + training_time + fitting_time} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dataset, tokenizer, model, learning_algo\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (651886343.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_42924/651886343.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    XXX stop here\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "XXX stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "\n",
    "if os.path.exists(results_file):\n",
    "    with open(results_file, 'rb') as fh:\n",
    "        results_d = pickle.load(fh)\n",
    "else:\n",
    "    results_d = {}\n",
    "\n",
    "    \n",
    "key = (pooling, mode, tfidf_dim, alpha, batch_size)\n",
    "results_d[key] = (test_results, \n",
    "                  tfidf_time + training_time + fitting_time, \n",
    "                  \"pooling - mode - tfidf_dim - alpha - batch_size\")\n",
    "\n",
    "with open(results_file, 'wb') as fh:\n",
    "    pickle.dump(results_d, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarks**\n",
    "\n",
    "- We chose to implement the **standard mean:** ``torch.mean(batch, dim=1)``: <br>\n",
    "    Instead of a custom mean where we sum the embedded tokens and divide by the sentence length, we implement a standard mean of the batch. After some experiments, this seems to work better.\n",
    "- Similarly, we chose to implement the **standard std:** ``torch.std(batch, dim=1)``: <br>\n",
    "    Instead of a custom std involving the sentence length, we implement a standard std of the batch. After some experiments, this seems to work better.\n",
    "- The **sorting by length** process infuences the results: <br>\n",
    "For some datasets, the results are better when the data are sorted by length, while for others, the opposite holds true. This phenomenon is probably due to the mean operation applied to the batch, which would yield very different results depending on whether the batch is sorted or not.\n",
    "- The **batch size** singificantly influences the results: <br>\n",
    "    Large batches include more padding than small batches. These padded tokens are actually involved in the computation of the mean, and thus influences it. For this reason, the batch size influences the results. The batch size will be a hyperparameter of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
