{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT with TF-IDF features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip # upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U huggingface-hub\n",
    "# !pip install -U scikit-learn\n",
    "# !pip install -U transformers\n",
    "# !pip install -U datasets\n",
    "# !pip install datasets==1.18.1\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tqdm progress bars (on a terminal):\n",
    "1. `conda install -c conda-forge nodejs`\n",
    "2. `jupyter labextension install @jupyter-widgets/jupyterlab-manager`\n",
    "3. `jupyter nbextension enable --py widgetsnbextension`\n",
    "4. `jupyter lab clean`\n",
    "5. Refresh web page..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import transformers\n",
    "import datasets\n",
    "# import huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current versions:\n",
      "1.0.2\n",
      "2.0.0\n",
      "4.18.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Current versions:\")\n",
    "print(sklearn.__version__)\n",
    "print(datasets.__version__)\n",
    "print(transformers.__version__)\n",
    "# print(huggingface_hub.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from transformers import BertModel, DistilBertModel\n",
    "from transformers.data.data_collator import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device and Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "cache_dir = 'cache_dir/'\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "tfidf_dim = 3000 # 4000\n",
    "\n",
    "alpha = 10\n",
    "learning_algo = RidgeClassifier(alpha=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functions for loading and preparing data\n",
    "\n",
    "def tokenize(sample, tokenizer):\n",
    "    \"\"\"Tokenize sample\"\"\"\n",
    "    \n",
    "    sample = tokenizer(sample['text'], truncation=True, padding=False, return_length=True)\n",
    "    \n",
    "    return sample\n",
    "\n",
    "def load_and_tokenize_dataset(dataset_name, model_name='bert-base-uncased', cache_dir='cache_dir/'):\n",
    "    \"\"\"\n",
    "    Load dataset from the datasets library of HuggingFace.\n",
    "    Tokenize and sort data by length.\n",
    "    \"\"\"\n",
    "    \n",
    "    # tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Load dataset\n",
    "    dataset = load_dataset(dataset_name, cache_dir=cache_dir)\n",
    "    \n",
    "    # Rename label column for tokenization purposes\n",
    "    dataset = dataset.rename_column('label', 'labels')\n",
    "    \n",
    "    # Tokenize data\n",
    "    dataset = dataset.map(lambda x: tokenize(x, tokenizer), batched=True)\n",
    "    \n",
    "    # sorting dataset\n",
    "    for split in dataset.keys():\n",
    "        dataset[split] = dataset[split].flatten_indices().sort(\"length\")\n",
    "    \n",
    "    return dataset, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.02 MiB, post-processed: Unknown size, total: 207.25 MiB) to cache_dir/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7d77240ee044359e69f74e4b19548e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imdb downloaded and prepared to cache_dir/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0e9fe876874a2f91c15bc5d8d2c868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ec83e56554446eb441b22faf5d88dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f08a501d8c4ce68a0b2e48283c4647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ef5c5e17e24231a5b8384737ab6f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a748cdfd2439401b8ba9cf411785f088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236d7111fc36428180121197ea588060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cdd60c29b2e4741a721fd295c7f25de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset, tokenizer = load_and_tokenize_dataset('imdb', model_name=model_name, cache_dir=cache_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask', 'length'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask', 'length'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask', 'length'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MemoryMappedTable\n",
       "indices: uint64\n",
       "----\n",
       "indices: [[340,14303,7796,20312,2809,17429,23421,10699,20570,16088,...,18432,12167,10979,14031,5795,1614,23205,5702,13899,20137],[3945,967,4769,10309,23471,18625,24657,10503,19083,14340,...,1762,21874,3403,2454,10963,21356,12233,2278,1644,24853],[14189,2755,22674,19072,1489,4587,3407,82,4848,18008,...,18499,9148,20490,20257,7327,18187,6109,21717,23407,21115],[4818,8905,16761,10976,11651,8144,1090,3710,13113,9613,...,13201,2202,23876,8790,22138,19887,9913,14505,5285,18855],[12854,12057,17948,11427,10499,18610,15817,13489,2385,15861,...,21291,6377,8057,18801,7733,9446,24643,12931,18094,7619],[14034,22119,20291,19070,16723,17657,3869,14703,18391,23153,...,12799,14271,23774,15793,5783,6446,14893,9100,4545,8879],[16469,804,17649,6141,15554,23508,4138,7022,23529,16649,...,8421,3903,7301,3547,7249,12658,3296,9283,6744,2110],[1892,1103,9798,24346,21949,6594,14182,18580,13214,22456,...,14037,22526,19119,12668,3026,13969,12427,24790,9730,14088],[15006,12231,3279,15237,17458,17794,9316,18548,7998,24931,...,5098,17127,7662,22098,4809,4813,23189,2738,9988,12199],[11550,10716,6924,23485,13238,12421,4146,4569,12940,23931,...,5309,19800,10386,7053,20661,13872,6358,22233,23252,13593],...[878,23899,11279,16767,13616,7103,17950,1321,16394,20392,...,16271,2501,5310,10246,7874,24827,1980,21282,11521,20313],[8434,8625,3007,14293,4947,22028,19384,9295,13573,24564,...,6342,13650,17817,4327,7882,24184,12816,17472,7210,4930],[9138,4466,10857,20496,10173,23331,12033,3361,11048,874,...,6287,24925,4347,6438,21,19268,104,3174,11655,21579],[16727,9769,1787,10341,8259,1023,4374,12147,5515,12562,...,7508,12648,24007,22378,9196,19566,14332,1012,22512,23495],[5616,23044,21189,10794,20526,10275,24710,16782,2628,2509,...,20016,23797,15721,8855,10025,3742,19239,2863,12946,17031],[10811,13168,17952,24562,2309,10643,19616,2550,15550,13426,...,16632,21590,10633,10370,569,17335,12979,1064,2597,19367],[7427,24665,18890,13536,21818,4592,18268,7034,23798,13025,...,19541,6231,24141,1827,3877,12768,4864,23588,20038,8290],[15447,17355,16420,19306,17205,24965,18977,19630,11314,10968,...,10803,1170,4827,8800,3198,6471,17122,8813,24577,1505],[4751,4659,19077,11472,17475,23769,5791,1190,461,1005,...,24253,14628,9733,7273,5224,5807,14793,23888,19681,15319],[14656,13682,9191,5894,20013,9475,18681,4123,14282,20835,...,10902,15535,8887,6050,7388,11044,6767,3162,9054,17672]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']._indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_features(dataset, dim=4000):\n",
    "    \"\"\"Compute tf-idf features and add it as a new field for the dataset\"\"\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_features=dim)\n",
    "    vectorizer.fit(dataset['train']['text'])\n",
    "        \n",
    "    for split in dataset.keys():\n",
    "        X_tmp = vectorizer.transform(dataset[split]['text'])\n",
    "        X_tmp = list(X_tmp.todense())\n",
    "        X_tmp = [np.asarray(row).reshape(-1) for row in X_tmp]\n",
    "        \n",
    "        indices = dataset[split]._indices # ***\n",
    "        dataset[split]._indices = None    # ***\n",
    "        dataset[split] = dataset[split].add_column(\"additional_fts\", X_tmp)\n",
    "        dataset[split]._indices = indices # ***\n",
    "        \n",
    "        dataset[split].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels', 'length', 'additional_fts'])\n",
    "        dataset[split] = dataset[split].remove_columns(\"text\")\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    return dataset, t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, tfidf_time = get_tfidf_features(dataset, dim=tfidf_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask', 'length', 'additional_fts'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask', 'length', 'additional_fts'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask', 'length', 'additional_fts'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.571083068847656"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([197, 238, 341,  ..., 174, 129, 294])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['length'] # not sorted!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MemoryMappedTable\n",
       "indices: uint64\n",
       "----\n",
       "indices: [[340,14303,7796,20312,2809,17429,23421,10699,20570,16088,...,18432,12167,10979,14031,5795,1614,23205,5702,13899,20137],[3945,967,4769,10309,23471,18625,24657,10503,19083,14340,...,1762,21874,3403,2454,10963,21356,12233,2278,1644,24853],[14189,2755,22674,19072,1489,4587,3407,82,4848,18008,...,18499,9148,20490,20257,7327,18187,6109,21717,23407,21115],[4818,8905,16761,10976,11651,8144,1090,3710,13113,9613,...,13201,2202,23876,8790,22138,19887,9913,14505,5285,18855],[12854,12057,17948,11427,10499,18610,15817,13489,2385,15861,...,21291,6377,8057,18801,7733,9446,24643,12931,18094,7619],[14034,22119,20291,19070,16723,17657,3869,14703,18391,23153,...,12799,14271,23774,15793,5783,6446,14893,9100,4545,8879],[16469,804,17649,6141,15554,23508,4138,7022,23529,16649,...,8421,3903,7301,3547,7249,12658,3296,9283,6744,2110],[1892,1103,9798,24346,21949,6594,14182,18580,13214,22456,...,14037,22526,19119,12668,3026,13969,12427,24790,9730,14088],[15006,12231,3279,15237,17458,17794,9316,18548,7998,24931,...,5098,17127,7662,22098,4809,4813,23189,2738,9988,12199],[11550,10716,6924,23485,13238,12421,4146,4569,12940,23931,...,5309,19800,10386,7053,20661,13872,6358,22233,23252,13593],...[878,23899,11279,16767,13616,7103,17950,1321,16394,20392,...,16271,2501,5310,10246,7874,24827,1980,21282,11521,20313],[8434,8625,3007,14293,4947,22028,19384,9295,13573,24564,...,6342,13650,17817,4327,7882,24184,12816,17472,7210,4930],[9138,4466,10857,20496,10173,23331,12033,3361,11048,874,...,6287,24925,4347,6438,21,19268,104,3174,11655,21579],[16727,9769,1787,10341,8259,1023,4374,12147,5515,12562,...,7508,12648,24007,22378,9196,19566,14332,1012,22512,23495],[5616,23044,21189,10794,20526,10275,24710,16782,2628,2509,...,20016,23797,15721,8855,10025,3742,19239,2863,12946,17031],[10811,13168,17952,24562,2309,10643,19616,2550,15550,13426,...,16632,21590,10633,10370,569,17335,12979,1064,2597,19367],[7427,24665,18890,13536,21818,4592,18268,7034,23798,13025,...,19541,6231,24141,1827,3877,12768,4864,23588,20038,8290],[15447,17355,16420,19306,17205,24965,18977,19630,11314,10968,...,10803,1170,4827,8800,3198,6471,17122,8813,24577,1505],[4751,4659,19077,11472,17475,23769,5791,1190,461,1005,...,24253,14628,9733,7273,5224,5807,14793,23888,19681,15319],[14656,13682,9191,5894,20013,9475,18681,4123,14282,20835,...,10902,15535,8887,6050,7388,11044,6767,3162,9054,17672]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']._indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(dataset, tokenizer, batch_size=256):\n",
    "    dataloader_d = {}\n",
    "\n",
    "    for split in ['train', 'test']:\n",
    "        dataloader_d[split] = torch.utils.data.DataLoader(dataset[split], \n",
    "                                                          batch_size=batch_size, \n",
    "                                                          collate_fn=DataCollatorWithPadding(tokenizer))\n",
    "        \n",
    "    return dataloader_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_d = create_dataloaders(dataset, tokenizer, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f74ac035700>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7f74ac035730>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in dataloader_d['train']:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "- **Embedding layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements an embedding layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name='bert-base-uncased', pooling='mean', device=torch.device('cpu')):\n",
    "        \n",
    "        \"\"\"\n",
    "        Constructor\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_name : str\n",
    "            Name of the BERT model and tokenizer.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        model_name : str\n",
    "            Name of the BERT model and tokenizer.\n",
    "            The list of or possible models is provided here: https://huggingface.co/models\n",
    "        pooling : str\n",
    "            Pooling strategy to be applied, either 'mean' or 'cls'.\n",
    "            For 'mean', the sentence embedding is the mean of the token embeddings.\n",
    "            For 'cls', the sentence embedding is the embedding of the [CSL] token (as usual in BERT).\n",
    "        device : torch.device\n",
    "            GPU is available, CPU otherwise.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Embedding, self).__init__()\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.pooling = pooling\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = BertModel.from_pretrained(self.model_name, output_hidden_states=True)\n",
    "        self.model.to(self.device).eval()\n",
    "        print('Model downloaded:', model_name)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "        Embeds a batch of token ids into a 3D tensor.\n",
    "        If a GPU is available, the embedded batch is computed and put on the GPU.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch: torch.Tensor\n",
    "            2D tensor: batch of text to be embedded.\n",
    "            Each sentence is represented as a vertical sequence of token ids.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        batch_emb : torch.Tensor\n",
    "            3D tensor (batch size x max sentence length x embedding dim)\n",
    "            BERT embedding of the batch of texts.\n",
    "        \"\"\"\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            batch = batch.to(self.device)\n",
    "            \n",
    "            # DOES NOT IMPROVE THE RESULTS \n",
    "#             # New attention mask with last 1 element - correposnding to [SEP] token - removed.\n",
    "#             # Accordingly, the mean pooling will not take the embedding of [SEP] into account.\n",
    "#             last_indices = batch['length'] - 1\n",
    "#             batch_size = batch['length'].shape[0]\n",
    "#             indices = torch.tensor([range(batch_size), last_indices]).transpose(0,1)\n",
    "#             # cf. https://discuss.pytorch.org/t/modify-array-with-list-of-indices/27739\n",
    "#             batch['attention_mask'][indices[:, 0], indices[:, 1]] = 0\n",
    "            \n",
    "            if self.pooling == 'mean':\n",
    "                \n",
    "                batch_emb = self.model(batch[\"input_ids\"], batch[\"attention_mask\"])[0]\n",
    "                # batch_emb = torch.mean(batch_emb, dim=1)\n",
    "                # batch_emb = batch_emb.transpose(0, 1)\n",
    "                # batch_emb = batch_emb[:, :, :] # removing CLS and/or SEP does not seem to improve\n",
    "                batch_emb = torch.sum(batch_emb, dim=1).transpose(0, 1)\n",
    "                batch_emb = torch.div(batch_emb, batch['length']).transpose(0, 1)\n",
    "            \n",
    "            elif self.pooling == 'cls':\n",
    "            \n",
    "                batch_emb = self.model(batch[\"input_ids\"], batch[\"attention_mask\"])[1]\n",
    "\n",
    "            return batch_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "#embedding = Embedding()\n",
    "embedding = Embedding(pooling='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert-base-uncased', 'mean', device(type='cuda'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.model_name, embedding.pooling, embedding.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = embedding(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 768])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **full model: embedding + feature concaatenation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTFIDF(nn.Module):\n",
    "    \"\"\"\n",
    "    Impdements BERT + TF-IDF model:\n",
    "    Concatenate BERT (or similar model) sentence embedding to most relevant TF-IDF features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='bert-base-uncased', device=torch.device('cpu')):\n",
    "        \n",
    "        super(BertTFIDF, self).__init__()\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.embedding = Embedding(model_name=self.model_name, device=self.device)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        embedded_input = self.embedding(batch)\n",
    "        additional_fts = batch['additional_fts']\n",
    "        \n",
    "        output = torch.cat([embedded_input, additional_fts], dim=1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['additional_fts'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "model = BertTFIDF(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset, model, batch_size=256):\n",
    "    \"\"\"\n",
    "    Pass a dataset into a model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : datasets.arrow_dataset.Dataset\n",
    "        Dataset to be processed\n",
    "    model : __main__.BertTFIDF\n",
    "        Model instance of the BertTFIDF class\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    outputs_t, labels_t : torch.Tensor, torch.Tensor\n",
    "        Tuple of outputs and labels resulting from passing the dataset into the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(dataset, \n",
    "                                             batch_size=batch_size, \n",
    "                                             collate_fn=DataCollatorWithPadding(tokenizer))\n",
    "    \n",
    "    outputs_t = torch.Tensor().to(device)\n",
    "    labels_t = torch.Tensor().to(device)\n",
    "\n",
    "    for i, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "\n",
    "        batch = batch.to(device)\n",
    "        outputs = model(batch)\n",
    "        outputs_t = torch.cat([outputs_t, outputs], dim=0)\n",
    "\n",
    "        labels = batch['labels']\n",
    "        labels_t = torch.cat([labels_t, labels], dim=0)\n",
    "    \n",
    "    outputs_t = outputs_t.cpu().numpy()\n",
    "    labels_t = labels_t.cpu().numpy()\n",
    "    \n",
    "    return outputs_t, labels_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = process_dataset(dataset['train'], model, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_learning_algo(learning_algo, dataset, model, batch_size=256):\n",
    "    \"\"\"\n",
    "    Train the learning algorithm associated with the supervised pb (X_train, y_train).\n",
    "    More specifically, after the train set is passed through the model (EMB + POOL + ADD_TF-IDF), \n",
    "    a vector of X_train of text emeddings concatenated with TF-IDF features is obtained.\n",
    "    Then, the association between X_train and y_train is learned by means of a learning algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, y_train = process_dataset(dataset['train'], model, batch_size=batch_size)\n",
    "    \n",
    "    # fit sklearn learning algo\n",
    "    learning_algo.fit(X_train, y_train)\n",
    "    \n",
    "    return learning_algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914716fd13694abda5ec8f2f792abbe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.89274e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "learning_algo = train_learning_algo(learning_algo, dataset, model, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(learning_algo, dataset, model, batch_size=256):\n",
    "    \"\"\"\n",
    "    Compute train and test predictions for the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    #X_train, y_train = process_dataset(dataset['train'], model, batch_size=batch_size)\n",
    "    #y_train_preds = learning_algo.predict(X_train)\n",
    "    y_train, y_train_preds = None, None\n",
    "    \n",
    "    X_test, y_test = process_dataset(dataset['test'], model, batch_size=batch_size)\n",
    "    y_test_preds = learning_algo.predict(X_test)\n",
    "    \n",
    "    return y_train, y_train_preds, y_test, y_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f920d4b04604a7eac1c3e2601847de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train, y_train_preds, y_test, y_test_preds = predict(learning_algo, dataset, model, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8472    0.8678    0.8573     12500\n",
      "         1.0     0.8645    0.8434    0.8538     12500\n",
      "\n",
      "    accuracy                         0.8556     25000\n",
      "   macro avg     0.8558    0.8556    0.8556     25000\n",
      "weighted avg     0.8558    0.8556    0.8556     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(classification_report(y_test, y_test_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does reproduce the results!!!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0     0.9431    0.9582    0.9506     12500\n",
    "         1.0     0.9575    0.9422    0.9498     12500\n",
    "\n",
    "    accuracy                         0.9502     25000\n",
    "   macro avg     0.9503    0.9502    0.9502     25000\n",
    "weighted avg     0.9503    0.9502    0.9502     25000\n",
    "\n",
    "transformers==4.18.0 / 0.4.0 datasets==2.0.0 / batch_size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After many experiments, the batch size seems to influence the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
